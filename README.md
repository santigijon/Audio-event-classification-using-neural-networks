# Audio-event-classification-using-artificial-neural-networks

In this repository the code developed during my master theis project ("Single and Multi-Label Environmental Sound Classification Using Convolutional Neural Networks") is presented. Several jupyter notebooks and python packages are available, as well as some audio files to make the jupyter notebook more interactive. 


## Contents

In the repository, four Jupyter notebooks can be found:

- Dataset_processing.ipynb
- Dataset_processing_Multilabel.ipynb
- Audio_Classification_Softmax_mine_260318.ipynb
- Audio_Classification_Multilabel_mine_170518.ipynb

And three Python modules:

- santiago_data_preprocessing.py
- santiago_my_modules_v3_160418.py
- santiago_my_modules_v3_17_05_18_Multilabel.py

In the two first Jupyter notebooks, the processing of the dataset is performed and explained, both for the single and the multi-label classification tasks. These two files make use of the Python module santiago_data_preprocessing.py
The two following Jupyter notebooks are the notebooks where the two models are implemented, making use of the two Python modules santiago_my_modules_v3_160418.py and santiago_my_modules_v3_17_05_18_Multilabel.py 


Hope you find it useful.
Any suggestion is always welcomed!
